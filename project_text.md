# é¡¹ç›®æ–‡æœ¬åŒ–æ€»è§ˆ

## é¡¹ç›®ç»“æ„æ ‘

```
â”œâ”€â”€ .gitignore
â”œâ”€â”€ AGENTS.md
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ generate_project_text.py
â”œâ”€â”€ project_text.md
â”œâ”€â”€ start.ps1
â”œâ”€â”€ stop.ps1
â”œâ”€â”€ test.html
â”œâ”€â”€ gateway/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ dto.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ worker_manager.py
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ dto.py
â”‚   â”œâ”€â”€ kernel_manager.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â””â”€â”€ simhei.ttf
â”‚   â”œâ”€â”€ supervisor/
â”‚   â”‚   â””â”€â”€ supervisord.conf
```

## æ–‡ä»¶å†…å®¹

--- 

`AGENTS.md`

```markdown
# ä»£ç è§„èŒƒ aka agents.md

## åŸºç¡€æ ¼å¼è§„èŒƒ
- æ‰€æœ‰çš„ä»£ç æ–‡ä»¶å¿…é¡»ä½¿ç”¨UTF-8ç¼–ç 
- æ‰€æœ‰çš„ä»£ç æ–‡ä»¶å¿…é¡»ä½¿ç”¨4ä¸ªç©ºæ ¼ç¼©è¿›ï¼Œä¸å…è®¸ä½¿ç”¨Tabç¼©è¿›
- PR/commitæ—¶ä¸è¦æœ‰ä»»ä½•è¯­æ³•é”™è¯¯ï¼ˆçº¢çº¿ï¼‰
- æ–‡ä»¶æœ«å°¾å¿…é¡»æœ‰ä¸€ä¸ªæ¢è¡Œç¬¦
- ä½¿ç”¨PyCharmé»˜è®¤çš„ä»£ç è§„èŒƒï¼ˆå˜é‡å‘½åï¼Œç±»å‘½åï¼Œæ¢è¡Œï¼Œç©ºæ ¼ï¼Œæ³¨é‡Šï¼‰ï¼ˆåœ¨é»˜è®¤æƒ…å†µä¸‹ä¸è¦å‡ºç°é»„çº¿ï¼Œæ˜æ˜¾æ˜¯linterçš„é”™è¯¯çš„é™¤å¤–ï¼‰

## ç±»å‹æ³¨è§£è§„èŒƒ
- æ‰€æœ‰çš„ç±»å‹æ³¨è§£éƒ½å¿…é¡»ä½¿ç”¨Python 3.10+çš„ç®€åŒ–è¯­æ³•
    - ä¾‹å¦‚ï¼šä½¿ç”¨ `dict[str, Any] | None` è€Œä¸æ˜¯ `Optional[Dict[str, Any]]`
    - **å”¯ä¸€ä¾‹å¤–**ï¼šç”¨å­—ç¬¦ä¸²è¡¨ç¤ºå¯ç©ºçš„ç±»å‹æ ‡æ³¨æ—¶ï¼Œä¸èƒ½ç”¨ `"TypeName" | None`ï¼ˆè¿™æ˜¯è¯­æ³•é”™è¯¯ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨ `Optional['TypeName']`
- å‚æ•°ã€ç±»å˜é‡ã€å®ä¾‹å˜é‡ç­‰å¿…é¡»æœ‰ç±»å‹æ³¨è§£ï¼Œå‡½æ•°è¿”å›å¿…é¡»è¦æ³¨æ˜ç±»å‹
- æ‰€æœ‰çš„ç±»å‹æ³¨è§£éƒ½å¿…é¡»æ˜¯æ˜ç¡®çš„ç±»å‹ï¼Œä¸èƒ½ä½¿ç”¨ `Any` æˆ– `object`ï¼Œé™¤éç¡®å®æ— æ³•ç¡®å®šç±»å‹ï¼Œ  
  éœ€è¦æ˜ç¡®ä½¿ç”¨todoæ ‡æ³¨ï¼Œä»¥ä¾¿åæœŸç ”ç©¶ç±»å‹
- æ‰€æœ‰çš„ç±»å‹æ³¨è§£éƒ½å¿…é¡»æ˜¯å…·ä½“çš„ç±»å‹ï¼Œä¸èƒ½ä½¿ç”¨æ³›å‹ï¼ˆå¦‚ `List`ã€`Dict`ã€`Tuple`ã€`Set`ã€`Union` ç­‰ï¼‰  
  å¿…é¡»ä½¿ç”¨å…·ä½“çš„ç±»å‹ï¼ˆå¦‚ `list[int]`ã€`dict[str, Any]`ã€`tuple[int, str]`ã€`set[str]`ã€`int | str` ç­‰ï¼‰
- æ‰€æœ‰çš„ç±»å‹æ³¨è§£éƒ½å¿…é¡»æ˜¯å¯¼å…¥çš„ç±»å‹ï¼Œä¸èƒ½ä½¿ç”¨å­—ç¬¦ä¸²è¡¨ç¤ºç±»å‹ï¼ˆå¦‚ `def func(param: 'CustomType') -> 'ReturnType':`ï¼‰  
  é™¤éæ˜¯**å‰å‘å¼•ç”¨**ï¼ˆå³ç±»å‹åœ¨å½“å‰ä½œç”¨åŸŸä¸­è¿˜æœªå®šä¹‰ï¼‰

## å¼‚æ­¥ç¼–ç¨‹è§„èŒƒ
- ä½¿ç”¨FastAPIç®¡ç†çš„äº‹ä»¶å¾ªç¯ï¼Œä¸è¦å†æ–°å»ºä»»ä½•äº‹ä»¶å¾ªç¯ï¼Œä¸è®ºæ˜¯åœ¨ä»»ä½•çº¿ç¨‹æˆ–ä»»ä½•å­è¿›ç¨‹ä¸­
- IOæ“ä½œå¿…é¡»ä½¿ç”¨åç¨‹ï¼Œä¸æ¶‰åŠä»»ä½•CPUå¯†é›†æˆ–IOçš„æ“ä½œå¿…é¡»ä¸ä½¿ç”¨åç¨‹ï¼ŒæŒ‰éœ€ä½¿ç”¨to_threadçº¿ç¨‹æˆ–Celery Worker
- æ‰€æœ‰çš„æ•°æ®åº“æ“ä½œå¿…é¡»ä½¿ç”¨å¼‚æ­¥æ•°æ®åº“é©±åŠ¨ï¼ˆå¦‚SQLModelçš„AsyncSessionï¼‰ï¼Œä¸å…è®¸ä½¿ç”¨åŒæ­¥æ•°æ®åº“é©±åŠ¨
- æ‰€æœ‰çš„HTTPè¯·æ±‚å¿…é¡»ä½¿ç”¨å¼‚æ­¥HTTPå®¢æˆ·ç«¯ï¼ˆå¦‚aiohttpï¼‰ï¼Œä¸å…è®¸ä½¿ç”¨åŒæ­¥HTTPå®¢æˆ·ç«¯
- æ‰€æœ‰çš„æ–‡ä»¶æ“ä½œå¿…é¡»ä½¿ç”¨å¼‚æ­¥æ–‡ä»¶æ“ä½œåº“ï¼ˆå¦‚aiofilesï¼‰ï¼Œä¸å…è®¸ä½¿ç”¨åŒæ­¥æ–‡ä»¶æ“ä½œ
- æ‰€æœ‰çš„å­è¿›ç¨‹æ“ä½œå¿…é¡»ä½¿ç”¨å¼‚æ­¥å­è¿›ç¨‹åº“ï¼ˆå¦‚anyioï¼‰ï¼Œä¸å…è®¸ä½¿ç”¨åŒæ­¥å­è¿›ç¨‹åº“
- æ‰€æœ‰çš„ç¬¬ä¸‰æ–¹åº“è°ƒç”¨å¿…é¡»ä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬ï¼Œä¸å…è®¸ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼Œå¦‚æœæ²¡æœ‰åŒæ­¥ç‰ˆæœ¬ï¼Œè§†cpuè´Ÿè½½æƒ…å†µä½¿ç”¨to_threadçº¿ç¨‹æˆ–Celery Worker
- æ‰€æœ‰çš„é«˜cpué˜»å¡æ“ä½œå¿…é¡»ä½¿ç”¨to_threadçº¿ç¨‹æˆ–Celery Workerï¼Œä¸å…è®¸åœ¨åç¨‹ä¸­ç›´æ¥è°ƒç”¨é«˜cpué˜»å¡æ“ä½œ

## å‡½æ•°ä¸å‚æ•°è§„èŒƒ
- ä¸€ä¸ªæ–¹æ³•æœ€å¤šäº”ä¸ªå‚æ•°ï¼Œå¤šäº†è€ƒè™‘æ‹†åˆ†æ–¹æ³•æˆ–åˆå¹¶å‚æ•°ï¼ˆSQLModelï¼‰ï¼Œä¸è¦ç®€å•çš„ç”¨tupleæˆ–dict

## ä»£ç æ ¼å¼è§„èŒƒ
- **å®¹å™¨ç±»å‹å®šä¹‰**ï¼šå…ƒç»„ã€å­—å…¸ã€åˆ—è¡¨å®šä¹‰æ—¶ï¼Œè‹¥å®šä¹‰åªç”¨äº†ä¸€è¡Œï¼Œåˆ™æœ€åä¸€ä¸ªå…ƒç´ åé¢ä¸€å¾‹ä¸åŠ é€—å·ï¼Œå¦åˆ™ä¸€å¾‹åŠ é€—å·
- **æ‹¬å·æ¢è¡Œ**ï¼šæ‹¬å·è¦ä¹ˆä¸æ¢è¡Œï¼Œè¦ä¹ˆæ¢è¡Œä¸”ç”¨ä¸‹é¢çš„å½¢å¼å†™ï¼ˆä¸€è¡Œæœ€å¤šä¸€ä¸ªå˜é‡ï¼Œä»¥é€—å·å’Œæ¢è¡Œåˆ†å‰²ï¼‰

### ç¤ºä¾‹ä»£ç 
```python
from loguru import logger as l

from api_client_models import (
    AgentModelsRequest,
    ReportRequest,
    SaveMemoryRequest,
    UserInfoResponse,
)

async def lookup_user_info(
        session: AsyncSession,
        user_id: int,
        short_name: str,
        data_1_with_a_long_name: dict[str, Any] | None,
        data_2_with_a_even_longer_name: CustomType
) -> UserInfoResponse:
    user = await User.get(session, User.id == user_id)
    new_dict = { user_id, short_name }
    l.debug(f"æŸ¥åˆ°çš„æ•°æ®: {new_dict}")
    result = UserInfoResponse(
        user.id,
        user.a_long_attribute,
        data_1_with_a_long_name,
        data_2_with_a_even_longer_name,
    )

    return result
```

## æ–‡æ¡£ä¸æ³¨é‡Šè§„èŒƒ
- å¤æ‚çš„ç±»æˆ–å‡½æ•°ï¼ˆæ— æ³•ä»åå­—æ¨æ–­æ˜ç¡®çš„æ“ä½œï¼Œå¦‚ `handle_connection()`ï¼‰ä¸€å¾‹è¦å†™docstringï¼Œé‡‡ç”¨reStructuredTexté£æ ¼

## å­—ç¬¦ä¸²å¤„ç†è§„èŒƒ
- **å¼•å·ä½¿ç”¨**ï¼šå•å¼•å· `'` ç”¨äºç»™ç”µè„‘çœ‹çš„æ–‡æœ¬ï¼ˆå­—å…¸çš„é”®ï¼‰ï¼ŒåŒå¼•å· `"` ç”¨äºç»™äººçœ‹çš„æ–‡æœ¬ï¼ˆé¢å‘ç”¨æˆ·çš„æç¤ºï¼Œé¢å‘å¼€å‘è€…çš„æ³¨é‡Šã€logä¿¡æ¯ç­‰ï¼‰
- **å­—ç¬¦ä¸²æ ¼å¼åŒ–**ï¼šæ‰€æœ‰çš„å­—ç¬¦ä¸²éƒ½ç”¨f-stringæ ¼å¼åŒ–ï¼Œä¸è¦ä½¿ç”¨ `%` æˆ– `.format()`
- **å¤šè¡Œå­—ç¬¦ä¸²**ï¼šå¤šè¡Œå­—ç¬¦ä¸²ä½¿ç”¨"""æˆ–'''ï¼Œ"""ç»™äººçœ‹(å¦‚docstring)ï¼Œ'''ç»™ç”µè„‘çœ‹ï¼ˆå¦‚SQLè¯­å¥æˆ–HTMLå†…å®¹ï¼‰

## å‘½åè§„èŒƒ
- é™¤éä¸“æœ‰åè¯ï¼Œä»£ç ä¸­ä¸è¦å‡ºç°ä»»ä½•æ‹¼éŸ³å˜é‡åï¼Œæ‰€æœ‰å˜é‡åå¿…é¡»æ˜¯è‹±æ–‡
- æ‰€æœ‰çš„å˜é‡åã€å‡½æ•°åã€æ–¹æ³•åã€å‚æ•°åéƒ½å¿…é¡»ä½¿ç”¨è›‡å½¢å‘½åæ³•ï¼ˆsnake_caseï¼‰
- æ‰€æœ‰çš„ç±»åéƒ½å¿…é¡»ä½¿ç”¨å¸•æ–¯å¡å‘½åæ³•ï¼ˆPascalCaseï¼‰
- æ‰€æœ‰çš„å¸¸é‡åéƒ½å¿…é¡»ä½¿ç”¨å…¨å¤§å†™è›‡å½¢å‘½åæ³•ï¼ˆUPPER_SNAKE_CASEï¼‰
- æ‰€æœ‰çš„ç§æœ‰å˜é‡ã€ç§æœ‰æ–¹æ³•éƒ½å¿…é¡»ä½¿ç”¨å•ä¸‹åˆ’çº¿å‰ç¼€ï¼ˆ_private_varï¼‰
- æ‰€æœ‰çš„éå¸¸ç§æœ‰å˜é‡ã€éå¸¸ç§æœ‰æ–¹æ³•éƒ½å¿…é¡»ä½¿ç”¨åŒä¸‹åˆ’çº¿å‰ç¼€ï¼ˆ__very_private_varï¼‰
- æ‰€æœ‰çš„å¸ƒå°”å˜é‡éƒ½å¿…é¡»ä½¿ç”¨is_ã€has_ã€can_ã€should_ç­‰å‰ç¼€å‘½åï¼Œä¸”å˜é‡åå¿…é¡»æ˜¯å½¢å®¹è¯æˆ–åŠ¨è¯çŸ­è¯­ï¼ˆå¦‚ is_valid, has_data, can_execute, should_retryï¼‰

## å¼‚å¸¸å¤„ç†è§„èŒƒ
- æ‰€æœ‰çš„å¼‚å¸¸éƒ½å¿…é¡»è¢«æ•è·ï¼Œä¸”è¦æœ‰æ˜ç¡®çš„å¤„ç†é€»è¾‘
- å¦‚æœå‡ºç°é”™è¯¯ï¼Œä¸è¦return Noneï¼Œè¿™æ ·ä¼šé€ æˆéšè—çš„ä¸æ˜“å‘ç°çš„é”™è¯¯ï¼Œå¿…é¡»æ˜ç¡®æŠ›å‡ºå¼‚å¸¸

## æ—¥å¿—å¤„ç†è§„èŒƒ
- æ‰€æœ‰çš„æ—¥å¿—éƒ½å¿…é¡»ç”¨ `from loguru import logger as l` å¤„ç†ï¼Œä¸è¦ä½¿ç”¨print
- æ‰€æœ‰çš„æ—¥å¿—éƒ½å¿…é¡»æœ‰æ˜ç¡®çš„ä¸Šä¸‹æ–‡ï¼Œä¸”è¦æœ‰æ˜ç¡®çš„æ—¥å¿—çº§åˆ«

## æ¡†æ¶çš„ä½¿ç”¨
- ä½¿ç”¨SQLModelï¼Œè€Œä¸æ˜¯Pydanticæˆ–SQLAlchemyã€‚ä½¿ç”¨SQLModelæ—¶ç¦æ­¢ä»futureå¯¼å…¥annotations
- ä½¿ç”¨FastAPIï¼Œè€Œä¸æ˜¯Flaskæˆ–Django
- ä½¿ç”¨Aiohttpï¼Œè€Œä¸æ˜¯Requests
- ä½¿ç”¨Aiofilesï¼Œè€Œä¸æ˜¯å†…ç½®çš„open
```python
import os as sync_os
from aiofiles import os, open
...
async with open('file.txt', 'r') as f:
    content = await f.read()
...
path = sync_os.path(...)
```
- ä½¿ç”¨Anyioï¼Œè€Œä¸æ˜¯å†…ç½®çš„subprocess
- ä½¿ç”¨Loguruï¼Œè€Œä¸æ˜¯å†…ç½®çš„logging
  `from loguru import logger as l`
- ä½¿ç”¨Celeryï¼Œè€Œä¸æ˜¯å†…ç½®çš„multiprocessing
- ä½¿ç”¨GitHub Desktopï¼Œè€Œä¸æ˜¯ç›´æ¥åœ¨æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
- ä½¿ç”¨PyCharmï¼Œè€Œä¸æ˜¯å…¶ä»–IDE

## AIç¼–ç 
- å¦‚æœæœ‰æ¡ä»¶ï¼Œinline completionæ’ä»¶ä½¿ç”¨GitHub Copilotï¼Œè€Œä¸æ˜¯JetBrainsè‡ªå¸¦çš„
- å¦‚æœè®©AIç›´æ¥ç¼–ç ï¼Œä½¿ç”¨Gemini 2.5 ProåŠä»¥ä¸Š, Claude 3.7 Sonnet ThinkingåŠä»¥ä¸Šï¼Œè€Œä¸æ˜¯GPTç³»åˆ—æ¨¡å‹ï¼ŒDeepSeekï¼Œè±†åŒ…ï¼Œæ–‡å¿ƒä¸€è¨€ç­‰
- ä½¿ç”¨AIç”Ÿæˆä»£ç æ—¶ï¼Œæç¤ºè¯å¿…é¡»å¸¦ä¸Šè¿™ä¸ªä»£ç è§„èŒƒ
- åœ¨å®ç°ä»»ä½•åŠŸèƒ½å‰ï¼Œå¿…é¡»å…ˆçœ‹çœ‹æœ‰æ²¡æœ‰ç°æˆçš„è§£å†³æ–¹æ¡ˆï¼Œæ¯”å¦‚pypiåŒ…ï¼Œä¸è¦é‡å¤é€ è½®å­

# SQLModelè§„èŒƒ
- ä½¿ç”¨å­—æ®µåé¢çš„"""..."""ï¼ˆdocstringï¼‰è€Œä¸æ˜¯å‚æ•°description="..."æ¥å†™å­—æ®µæè¿°
  ä¾‹å¦‚ï¼š
```python
class User(SQLModel, table=True):
    model_config = ConfigDict(use_attribute_docstrings=True)

    id: int = Field(default=None, primary_key=True, description="ç”¨æˆ·ID")  # é”™è¯¯ç¤ºèŒƒ
    name: str = Field(description="ç”¨æˆ·å")  # é”™è¯¯ç¤ºèŒƒ
    email: str = Field(unique=True)  # æ­£ç¡®ç¤ºèŒƒ
    """ç”¨æˆ·é‚®ç®±"""
```

  
---

**æ³¨æ„**ï¼šæ­¤è§„èŒƒä¼šæŒç»­æ›´æ–°ï¼Œå¯¹æ­¤æ–‡ä»¶æœ‰ä»»ä½•å»ºè®®ä¿®æ”¹å¯ä»¥å‘èµ·PRï¼Œæ²¡æœ‰åœ¨è§„èŒƒé‡Œæåˆ°çš„éƒ½æ²¡æœ‰ç¡¬æ€§è¦æ±‚ï¼Œå¯ä»¥å‚è€ƒ[PEP 8](https://peps.python.org/pep-0008/)

```

--- 

`README.md`

```markdown
# Code Interpreter - é«˜æ€§èƒ½ã€å¯ä¼¸ç¼©ã€é«˜å®‰å…¨æ€§çš„ Python ä»£ç æ²™ç®±

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé€šè¿‡ API é©±åŠ¨çš„ Python ä»£ç æ‰§è¡Œæ²™ç®±ã€‚å®ƒé‡‡ç”¨ä¸­å¿ƒåŒ–çš„ **API ç½‘å…³ (Gateway)** å’ŒåŠ¨æ€çš„ **å·¥ä½œå®ä¾‹æ±  (Worker Pool)** æ¶æ„ï¼Œä¸ºæ¯ä¸ªç”¨æˆ·æä¾›å®Œå…¨éš”ç¦»çš„ã€æœ‰çŠ¶æ€çš„ Python æ‰§è¡Œä¼šè¯ã€‚

æ¯ä¸ªå·¥ä½œå®ä¾‹éƒ½åœ¨ä¸€ä¸ªç‹¬ç«‹çš„ã€å—èµ„æºå’Œç½‘ç»œé™åˆ¶çš„ Docker å®¹å™¨ä¸­è¿è¡Œï¼Œå¹¶é€šè¿‡å†…éƒ¨çš„ Jupyter Kernel ä¿æŒä»£ç æ‰§è¡Œçš„ä¸Šä¸‹æ–‡çŠ¶æ€ï¼Œæä¾›äº†æè‡´çš„å®‰å…¨æ€§ã€ä¼šè¯è¿ç»­æ€§å’Œé«˜æ€§èƒ½ã€‚

## æ ¸å¿ƒç‰¹æ€§

-   **æœ‰çŠ¶æ€ä¼šè¯**: æ¯ä¸ªç”¨æˆ· (é€šè¿‡ `user_uuid` æ ‡è¯†) åœ¨ä¼šè¯æœŸé—´ä¼šè¢«å”¯ä¸€åœ°æ˜ å°„åˆ°ä¸€ä¸ªå·¥ä½œå®ä¾‹ï¼Œä»è€Œä¿è¯äº†å˜é‡ã€å‡½æ•°å®šä¹‰å’Œå¯¼å…¥çš„åŒ…åœ¨è¿ç»­çš„ API è¯·æ±‚ä¹‹é—´å¾—ä»¥ä¿æŒã€‚

-   **æè‡´éš”ç¦»ä¸å®‰å…¨**:
    -   **ä¸­å¿ƒåŒ–è®¿é—®æ§åˆ¶**: æ‰€æœ‰çš„è¯·æ±‚éƒ½å¿…é¡»é€šè¿‡ API ç½‘å…³ï¼Œç½‘å…³è´Ÿè´£ç»Ÿä¸€çš„ä»¤ç‰Œè®¤è¯ï¼Œå·¥ä½œå®ä¾‹ä¸ç›´æ¥æš´éœ²äºå¤–éƒ¨ã€‚
    -   **ç½‘ç»œéš”ç¦»**: æ‰€æœ‰å·¥ä½œå®ä¾‹éƒ½è¿è¡Œåœ¨ä¸€ä¸ª**å®Œå…¨éš”ç¦»çš„ Docker å†…éƒ¨ç½‘ç»œ**ä¸­ã€‚è¿™æ„å‘³ç€å·¥ä½œå®ä¾‹æ— æ³•è®¿é—®äº’è”ç½‘ï¼Œä¹Ÿæ— æ³•è¢«å¤–éƒ¨ç½‘ç»œç›´æ¥è®¿é—®ï¼Œæœ‰æ•ˆé˜²æ­¢äº†æ•°æ®å¤–æ³„å’Œæ¶æ„ä»£ç çš„ç½‘ç»œæ”»å‡»ã€‚
    -   **è¿›ç¨‹/èµ„æºéš”ç¦»**: æ¯ä¸ªå·¥ä½œå®ä¾‹è¿è¡Œåœ¨ç‹¬ç«‹çš„ Docker å®¹å™¨ä¸­ï¼Œå®ç°äº†æ“ä½œç³»ç»Ÿçº§åˆ«çš„èµ„æºéš”ç¦»ã€‚

-   **é«˜æ€§èƒ½ä¸é«˜å¹¶å‘**:
    -   **æ± åŒ–æ¶æ„**: ç³»ç»Ÿç»´æŠ¤ä¸€ä¸ªé¢„çƒ­çš„ç©ºé—²å·¥ä½œå®ä¾‹æ± ã€‚å½“ç”¨æˆ·é¦–æ¬¡è¯·æ±‚æ—¶ï¼Œç½‘å…³ä¼šç«‹å³ä»æ± ä¸­åˆ†é…ä¸€ä¸ªå®ä¾‹ï¼Œå®ç°äº†è¿‘ä¹é›¶å»¶è¿Ÿçš„æ²™ç®±ç¯å¢ƒè·å–ã€‚
    -   **å…¨å¼‚æ­¥è®¾è®¡**: ç½‘å…³å’Œå·¥ä½œå®ä¾‹å‡åŸºäº FastAPI æ„å»ºï¼Œæ•´ä¸ªè¯·æ±‚å¤„ç†é“¾è·¯å®Œå…¨å¼‚æ­¥åŒ–ï¼Œèƒ½å¤Ÿè½»æ¾å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚ã€‚

-   **é«˜é²æ£’æ€§ä¸è‡ªæ„ˆèƒ½åŠ›**:
    -   **å¥åº·æ£€æŸ¥**: ç½‘å…³åœ¨åˆ›å»ºå¹¶åˆ†é…å·¥ä½œå®ä¾‹å‰ä¼šå¯¹å…¶è¿›è¡Œä¸¥æ ¼çš„å¥åº·æ£€æŸ¥ï¼Œç¡®ä¿å†…éƒ¨æœåŠ¡å®Œå…¨å°±ç»ªã€‚
    -   **è¶…æ—¶è‡ªåŠ¨é‡ç½®**: å½“ä»£ç æ‰§è¡Œæ—¶é—´è¶…è¿‡é¢„è®¾é˜ˆå€¼æ—¶ï¼Œå·¥ä½œå®ä¾‹å†…éƒ¨çš„ Jupyter Kernel ä¼šè¢«è‡ªåŠ¨é‡ç½®ï¼Œä»¥é˜²æ­»å¾ªç¯æˆ–é•¿æ—¶é—´çš„é˜»å¡æ“ä½œæ‹–å®ç¯å¢ƒã€‚
    -   **é—²ç½®è‡ªåŠ¨å›æ”¶**: ç½‘å…³çš„åå°ä»»åŠ¡ä¼šå‘¨æœŸæ€§åœ°æ£€æŸ¥å¹¶å›æ”¶é•¿æ—¶é—´æœªæ´»åŠ¨çš„å®ä¾‹ï¼Œè‡ªåŠ¨é‡Šæ”¾èµ„æºï¼Œå¹¶ç»´æŒæ± ä¸­æœ€å°ç©ºé—²å®ä¾‹æ•°ã€‚
    -   **ä¼šè¯ä¸»åŠ¨é‡Šæ”¾**: æä¾›äº† `/release` æ¥å£ï¼Œå…è®¸ç”¨æˆ·ä¸»åŠ¨ç»“æŸä¼šè¯å¹¶ç«‹å³é”€æ¯å…¶å®ä¾‹ï¼Œé‡Šæ”¾èµ„æºã€‚

## æ¶æ„è§£æ

é¡¹ç›®ä¸»è¦ç”±ä¸¤å¤§éƒ¨åˆ†ç»„æˆï¼š**API ç½‘å…³ (Gateway)** å’Œ **å·¥ä½œå®ä¾‹ (Worker)**ã€‚

1.  **API ç½‘å…³ (Gateway)**
    *   ä½œä¸ºç³»ç»Ÿçš„å”¯ä¸€å…¥å£ï¼Œè´Ÿè´£æ¥æ”¶æ‰€æœ‰å¤–éƒ¨ API è¯·æ±‚ã€‚
    *   **è®¤è¯ä¸­å¿ƒ**: æ ¡éªŒæ‰€æœ‰è¯·æ±‚å¤´ä¸­çš„ `X-Auth-Token`ã€‚
    *   **å·¥ä½œæ± ç®¡ç†å™¨ (`WorkerManager`)**:
        *   ç»´æŠ¤ä¸€ä¸ªç”± `Worker` å®¹å™¨ç»„æˆçš„æ± ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæœ€å°æ•°é‡çš„ç©ºé—²å®ä¾‹ã€‚
        *   å½“æ¥æ”¶åˆ°æ–°ç”¨æˆ·çš„è¯·æ±‚æ—¶ï¼Œä»æ± ä¸­å–å‡ºä¸€ä¸ªç©ºé—²å®ä¾‹å¹¶ä¸è¯¥ç”¨æˆ·çš„ `user_uuid` ç»‘å®šã€‚
        *   å¦‚æœæ± ä¸­æ²¡æœ‰ç©ºé—²å®ä¾‹ä¸”æœªè¾¾åˆ°æ€»æ•°ä¸Šé™ï¼Œåˆ™åŠ¨æ€åˆ›å»ºæ–°çš„å®ä¾‹ã€‚
        *   è´Ÿè´£å®ä¾‹çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ŒåŒ…æ‹¬åˆ›å»ºã€å¥åº·æ£€æŸ¥ã€é—²ç½®å›æ”¶å’Œé”€æ¯ã€‚
    *   **è¯·æ±‚ä»£ç†**: å°†å·²è®¤è¯å’Œåˆ†é…çš„è¯·æ±‚ï¼Œé€æ˜åœ°ä»£ç†åˆ°å¯¹åº”çš„å†…éƒ¨å·¥ä½œå®ä¾‹ä¸Šã€‚

2.  **å·¥ä½œå®ä¾‹ (Worker)**
    *   ä¸€ä¸ªæ ‡å‡†åŒ–çš„ã€è‡ªåŒ…å«çš„ Docker å®¹å™¨ï¼Œæ˜¯å®é™…çš„ä»£ç æ‰§è¡Œå•å…ƒã€‚
    -   å®¹å™¨å†…éƒ¨ç”± `Supervisor` ç®¡ç†ä¸¤ä¸ªæ ¸å¿ƒè¿›ç¨‹ï¼š
        *   **Jupyter Kernel**: æä¾›ä¸€ä¸ªæœ‰çŠ¶æ€çš„ Python è¿è¡Œæ—¶ç¯å¢ƒã€‚è¿™æ˜¯å®ç°ä¼šè¯è¿ç»­æ€§çš„å…³é”®ã€‚
        *   **FastAPI æœåŠ¡**: æš´éœ²ä¸€ä¸ªç®€å•çš„å†…éƒ¨ HTTP API (`/execute`, `/reset`, `/health`)ï¼Œæ¥æ”¶æ¥è‡ªç½‘å…³çš„æŒ‡ä»¤ã€‚
    *   **å†…æ ¸ç®¡ç†å™¨ (`JupyterKernelManager`)**:
        *   FastAPI æœåŠ¡é€šè¿‡è¯¥æ¨¡å—ä¸ Jupyter Kernel è¿›è¡Œäº¤äº’ï¼Œé€šè¿‡ WebSocket å‘é€ä»£ç å¹¶å®æ—¶æ•è·è¾“å‡ºã€å›¾åƒæˆ–é”™è¯¯ã€‚

## å¿«é€Ÿå¼€å§‹

### 1. å‰ææ¡ä»¶

-   [Docker](https://www.docker.com/) å’Œ [Docker Compose](https://docs.docker.com/compose/) å·²æ­£ç¡®å®‰è£…å¹¶æ­£åœ¨è¿è¡Œã€‚
-   ä¸€ä¸ªå¯ä»¥å‘é€ HTTP è¯·æ±‚çš„å®¢æˆ·ç«¯ (å¦‚ cURL, Postman, æˆ–è€… Python çš„ `httpx` åº“)ã€‚

### 2. å¯åŠ¨æœåŠ¡

æœ¬é¡¹ç›®è¢«è®¾è®¡ä¸ºä½¿ç”¨ Docker Compose è¿›è¡Œä¸€é”®éƒ¨ç½²ã€‚

1.  **æ„å»ºå¹¶å¯åŠ¨æœåŠ¡**
    åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

    ```bash
    docker-compose up --build -d
    ```

    æ­¤å‘½ä»¤ä¼šï¼š
    -   æ„å»º `gateway` å’Œ `worker` çš„ Docker é•œåƒã€‚
    -   åˆ›å»ºä¸€ä¸ªåä¸º `code-interpreter_workers_isolated_net` çš„éš”ç¦»å†…éƒ¨ç½‘ç»œã€‚
    -   å¯åŠ¨ç½‘å…³æœåŠ¡ï¼Œå¹¶å°†å…¶ `3874` ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ `3874` ç«¯å£ã€‚
    -   æ ¹æ®ç½‘å…³çš„é…ç½® (`gateway/config.py`)ï¼Œè‡ªåŠ¨åˆå§‹åŒ–å·¥ä½œæ± ã€‚

2.  **è·å–è®¤è¯ä»¤ç‰Œ**
    æœåŠ¡é¦–æ¬¡å¯åŠ¨æ—¶ï¼Œä¸€ä¸ªè®¤è¯ä»¤ç‰Œä¼šè‡ªåŠ¨åœ¨ `gateway/` ç›®å½•ä¸‹ç”Ÿæˆï¼Œæ–‡ä»¶åä¸º `auth_token.txt`ã€‚ä½ ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `AUTH_TOKEN` æ¥è‡ªå®šä¹‰ä»¤ç‰Œã€‚

## API æ¥å£æ–‡æ¡£

æ‰€æœ‰ API è¯·æ±‚éƒ½åº”å‘é€åˆ° Gateway åœ°å€ (é»˜è®¤ä¸º `http://127.0.0.1:3874`)ã€‚

### è®¤è¯

æ‰€æœ‰æ¥å£éƒ½éœ€è¦åœ¨ HTTP è¯·æ±‚å¤´ä¸­æä¾›è®¤è¯ä»¤ç‰Œã€‚
-   **Header**: `X-Auth-Token`
-   **Value**: `ä½ çš„è®¤è¯ä»¤ç‰Œ`

---

### 1. æ‰§è¡Œä»£ç 

åœ¨ç”¨æˆ·çš„ä¼šè¯ä¸­æ‰§è¡Œä¸€æ®µ Python ä»£ç ã€‚

-   **Endpoint**: `POST /execute`
-   **æè¿°**: ä¸ºæŒ‡å®šçš„ `user_uuid` åˆ†é…ä¸€ä¸ªå·¥ä½œå®ä¾‹ï¼ˆå¦‚æœå°šä¸å­˜åœ¨ï¼‰ï¼Œç„¶ååœ¨è¯¥å®ä¾‹ä¸­æ‰§è¡Œä»£ç ã€‚åç»­ä½¿ç”¨ç›¸åŒ `user_uuid` çš„è¯·æ±‚å°†åœ¨åŒä¸€ä¸ªå®ä¾‹ä¸­æ‰§è¡Œï¼Œä»è€Œç»´æŒçŠ¶æ€ã€‚
-   **Request Body**:
    ```json
    {
      "user_uuid": "string",
      "code": "string"
    }
    ```
    -   `user_uuid` (string, required): ç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚å»ºè®®ä½¿ç”¨ UUIDã€‚
    -   `code` (string, required): éœ€è¦æ‰§è¡Œçš„ Python ä»£ç å­—ç¬¦ä¸²ã€‚

-   **Success Response (200 OK)**:
    ```json
    {
      "result_text": "string | null",
      "result_base64": "string | null"
    }
    ```
    -   `result_text`: ä»£ç çš„æ ‡å‡†è¾“å‡º (stdout) æˆ–æœ€åä¸€ä¸ªè¡¨è¾¾å¼çš„æ–‡æœ¬è¡¨ç¤ºã€‚
    -   `result_base64`: å¦‚æœä»£ç ç”Ÿæˆäº†å›¾åƒ (ä¾‹å¦‚ä½¿ç”¨ matplotlib)ï¼Œæ­¤å­—æ®µå°†åŒ…å« PNG å›¾åƒçš„ Base64 ç¼–ç å­—ç¬¦ä¸²ã€‚

-   **Error Responses**:
    -   `400 Bad Request`: ä»£ç æ‰§è¡Œå‡ºé”™ï¼ˆä¾‹å¦‚è¯­æ³•é”™è¯¯ï¼‰æˆ–æ‰§è¡Œè¶…æ—¶ã€‚
    -   `401 Unauthorized`: è®¤è¯ä»¤ç‰Œæ— æ•ˆæˆ–ç¼ºå¤±ã€‚
    -   `503 Service Unavailable`: å·¥ä½œæ± å·²æ»¡ï¼Œæš‚æ—¶æ²¡æœ‰å¯ç”¨çš„å·¥ä½œå®ä¾‹ã€‚

---

### 2. é‡Šæ”¾ä¼šè¯

ä¸»åŠ¨ç»“æŸä¸€ä¸ªç”¨æˆ·çš„ä¼šè¯å¹¶é”€æ¯å…¶å…³è”çš„å·¥ä½œå®ä¾‹ã€‚

-   **Endpoint**: `POST /release`
-   **æè¿°**: ç«‹å³å›æ”¶æŒ‡å®š `user_uuid` å ç”¨çš„èµ„æºã€‚å¦‚æœä¸ä¸»åŠ¨è°ƒç”¨ï¼Œå®ä¾‹ä¹Ÿä¼šåœ¨é—²ç½®è¶…æ—¶åè¢«ç³»ç»Ÿè‡ªåŠ¨å›æ”¶ã€‚
-   **Request Body**:
    ```json
    {
      "user_uuid": "string"
    }
    ```
    -   `user_uuid` (string, required): éœ€è¦é‡Šæ”¾çš„ä¼šè¯çš„ç”¨æˆ·æ ‡è¯†ç¬¦ã€‚

-   **Success Response (200 OK)**:
    ```json
    {
      "status": "ok",
      "detail": "Worker for user <user_uuid> has been released."
    }
    ```

---

### 3. è·å–ç³»ç»ŸçŠ¶æ€ (ç®¡ç†æ¥å£)

æŸ¥è¯¢å½“å‰å·¥ä½œæ± çš„çŠ¶æ€ã€‚

-   **Endpoint**: `GET /status`
-   **æè¿°**: è¿”å›å…³äºå·¥ä½œå®ä¾‹æ•°é‡å’ŒçŠ¶æ€çš„æ‘˜è¦ä¿¡æ¯ï¼Œä¸»è¦ç”¨äºç›‘æ§å’Œè°ƒè¯•ã€‚
-   **Request Body**: None
-   **Success Response (200 OK)**:
    ```json
    {
        "total_workers": 10,
        "busy_workers": 3,
        "idle_workers_in_pool": 2,
        "is_initializing": false
    }
    ```

## ä½¿ç”¨ç¤ºä¾‹ (Python)

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ `httpx` åº“ä¸æœåŠ¡äº¤äº’çš„å®Œæ•´ç¤ºä¾‹ã€‚

```python
import httpx
import asyncio
import uuid
import base64
import os

# --- é…ç½® ---
GATEWAY_URL = "http://127.0.0.1:3874"
# ä» gateway/auth_token.txt æ–‡ä»¶ä¸­è·å–
AUTH_TOKEN = "your-actual-auth-token" 
# ä¸ºè¿™ä¸ªä¼šè¯ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ç”¨æˆ· ID
USER_ID = str(uuid.uuid4())

HEADERS = {"X-Auth-Token": AUTH_TOKEN}

async def execute_code(client: httpx.AsyncClient, session_id: str, code: str):
    """ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºå‘é€æ‰§è¡Œè¯·æ±‚å¹¶æ‰“å°ç»“æœã€‚"""
    print(f"\n--- æ­£åœ¨æ‰§è¡Œä»£ç  ---\n{code.strip()}")
    payload = {"user_uuid": session_id, "code": code}
    
    try:
        response = await client.post(f"{GATEWAY_URL}/execute", json=payload, headers=HEADERS)
        response.raise_for_status() # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        
        data = response.json()
        if data.get("result_text"):
            print(">>> æ–‡æœ¬ç»“æœ:\n" + data["result_text"])
        if data.get("result_base64"):
            print(">>> æˆåŠŸç”Ÿæˆå›¾åƒï¼(è¿”å› base64 ç¼–ç çš„ PNG æ•°æ®)")
            # å¯é€‰ï¼šå°†å›¾åƒæ•°æ®ä¿å­˜åˆ°æ–‡ä»¶
            img_data = base64.b64decode(data["result_base64"])
            output_filename = f"output_{session_id[:8]}.png"
            with open(output_filename, "wb") as f:
                f.write(img_data)
            print(f"    å›¾åƒå·²ä¿å­˜ä¸º {output_filename}")
            
    except httpx.HTTPStatusError as e:
        print(f"æ‰§è¡Œå¤±è´¥: {e.response.status_code} - {e.response.text}")
    except httpx.RequestError as e:
        print(f"è¯·æ±‚é”™è¯¯: {e}")


async def release_session(client: httpx.AsyncClient, session_id: str):
    """è¾…åŠ©å‡½æ•°ï¼Œç”¨äºé‡Šæ”¾ä¼šè¯ã€‚"""
    print("\n--- æ­£åœ¨é‡Šæ”¾å·¥ä½œå®ä¾‹ ---")
    release_payload = {"user_uuid": session_id}
    response = await client.post(f"{GATEWAY_URL}/release", json=release_payload, headers=HEADERS)
    if response.status_code == 200:
        print("æˆåŠŸé‡Šæ”¾:", response.json().get('detail'))
    else:
        print("é‡Šæ”¾å¤±è´¥:", response.text)


async def main():
    async with httpx.AsyncClient(timeout=30.0) as client:
        # ç¤ºä¾‹ 1: å®šä¹‰å˜é‡
        await execute_code(client, USER_ID, "a = 10\nb = 20")
        
        # ç¤ºä¾‹ 2: å¤ç”¨ä¸Šä¸€æ¬¡æ‰§è¡Œçš„å˜é‡ 'a' å’Œ 'b' (æœ‰çŠ¶æ€)
        await execute_code(client, USER_ID, "result = a * b\nprint(f'The product is {result}')\nresult")

        # ç¤ºä¾‹ 3: ç”Ÿæˆä¸€ä¸ªå›¾åƒ (matplotlib)
        matplotlib_code = """
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(5, 3))
plt.plot(x, y)
plt.title('Sine Wave')
plt.grid(True)
plt.show()
        """
        await execute_code(client, USER_ID, matplotlib_code)

        # ç¤ºä¾‹ 4: ä¸»åŠ¨é‡Šæ”¾ä¼šè¯å’Œèµ„æº
        await release_session(client, USER_ID)


if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»¤ç‰Œ
    if AUTH_TOKEN == "your-actual-auth-token":
        # å°è¯•ä»æ–‡ä»¶ä¸­è¯»å–ä»¤ç‰Œ
        try:
            with open(os.path.join("gateway", "auth_token.txt"), "r") as f:
                AUTH_TOKEN = f.read().strip()
                HEADERS["X-Auth-Token"] = AUTH_TOKEN
        except FileNotFoundError:
             print("é”™è¯¯: è¯·å°† AUTH_TOKEN å˜é‡æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»¤ç‰Œï¼Œæˆ–ç¡®ä¿ gateway/auth_token.txt æ–‡ä»¶å­˜åœ¨ã€‚")
             exit(1)
             
    asyncio.run(main())
```

## Roadmap

-   [ ] å¢åŠ æ–‡ä»¶ä¸Šä¼ ä¸‹è½½åŠŸèƒ½
-   [ ] å¢åŠ  `site-packages` çš„æŒä¹…åŒ–å­˜å‚¨
-   [ ] æ›´ç²¾ç»†åŒ–çš„èµ„æºé™åˆ¶ (CPU, å†…å­˜)
-   [ ] æ”¯æŒè‡ªå®šä¹‰ Python ç¯å¢ƒå’Œé¢„è£…åº“

```

--- 

`docker-compose.yml`

```
# docker-compose.yml

version: '3.8'

services:
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    image: code-interpreter-gateway:latest
    container_name: code-interpreter_gateway
    restart: unless-stopped
    ports:
      # æ˜ å°„ Gateway å¯¹å¤–ç«¯å£ï¼Œæ ¹æ®æ‚¨çš„ Dockerfileï¼Œè¿™é‡Œæ˜¯ 3874
      - "3874:3874"
    volumes:
      # å°†å®¿ä¸»æœºçš„ Docker socket æŒ‚è½½åˆ°å®¹å™¨å†…ï¼Œä»¥ä¾¿ Gateway å¯ä»¥ç®¡ç†å…¶ä»–å®¹å™¨
      - /var/run/docker.sock:/var/run/docker.sock
      # æŒ‚è½½ä¸€ä¸ªå·ç”¨äºæŒä¹…åŒ– auth_token
      - gateway_data:/gateway
    networks:
      # [æ–°å¢] è¿æ¥åˆ°å¤–éƒ¨ç½‘ç»œï¼ˆé»˜è®¤æ¡¥æ¥ï¼‰ï¼Œä»¥ä¾¿ Gateway è‡ªèº«å¯ä»¥è®¿é—®äº’è”ç½‘
      - code-interpreter-gateway-external-net
      # [æ›´æ–°] è¿æ¥åˆ°å†…éƒ¨éš”ç¦»ç½‘ç»œï¼Œä»¥ä¾¿ Gateway å¯ä»¥ä¸ Worker é€šä¿¡
      - code-interpreter-workers-isolated-net
    environment:
      # ç¡®ä¿ Gateway çŸ¥é“è¦å°† Worker è¿æ¥åˆ°å“ªä¸ªå†…éƒ¨ç½‘ç»œ
      - INTERNAL_NETWORK_NAME=code-interpreter_workers_isolated_net
    depends_on:
      - worker # ç¡®ä¿ worker é•œåƒè¢«æ„å»º

  worker:
    build:
      context: ./worker
      dockerfile: Dockerfile
    image: code-interpreter-worker:latest
    container_name: code-interpreter_worker_builder # ç»™ builder å®¹å™¨ä¸€ä¸ªå›ºå®šåå­—ï¼Œæ–¹ä¾¿æ¸…ç†
    entrypoint: /bin/true # è¦†ç›– ENTRYPOINTï¼Œä½¿å…¶ç«‹å³é€€å‡º
    networks:
      # [æ›´æ–°] åªè¿æ¥åˆ°å†…éƒ¨éš”ç¦»ç½‘ç»œã€‚è¿™ä¸ª builder å®¹å™¨æœ¬èº«ä¸åº”éœ€è¦äº’è”ç½‘
      - code-interpreter-workers-isolated-net

networks:
  # [æ–°å¢] Gateway å¤–éƒ¨ç½‘ç»œï¼ˆæ ‡å‡†æ¡¥æ¥ï¼‰ï¼Œå…è®¸ Gateway è®¿é—®äº’è”ç½‘
  code-interpreter-gateway-external-net:
    driver: bridge
    name: code-interpreter_gateway_external_net

  # [æ–°å¢ & å…³é”®] Worker å†…éƒ¨éš”ç¦»ç½‘ç»œã€‚internal: true æ˜¯éš”ç¦»çš„å…³é”®ï¼
  code-interpreter-workers-isolated-net:
    driver: bridge
    internal: true # <--- è¿™ä¸€è¡Œæ˜¯ç¡®ä¿ Worker æ— æ³•è”ç½‘çš„å…³é”®
    name: code-interpreter_workers_isolated_net

volumes:
  gateway_data:

```

--- 

`gateway\Dockerfile`

```
FROM python:3.12-slim-bookworm

LABEL maintainer="Foxerine"
LABEL description="Gateway and manager for the Python code interpreter."

ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    PYTHONUNBUFFERED=1

WORKDIR /gateway
COPY ./requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt && rm /tmp/requirements.txt

COPY . /gateway

EXPOSE 3874
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "3874"]

```

--- 

`gateway\config.py`

```python
# gateway/config.py

"""
Centralized configuration for the Gateway service.
"""
import os
import uuid
from pathlib import Path

from loguru import logger as l

# --- Authentication ---
# The master token required to use the gateway services.
def get_auth_token():
    token_file = Path("/gateway/auth_token.txt")
    if "AUTH_TOKEN" in os.environ:
        return os.environ["AUTH_TOKEN"]
    elif token_file.exists():
        return token_file.read_text().strip()
    else:
        new_token = str(uuid.uuid4())
        token_file.write_text(new_token)
        return new_token

AUTH_TOKEN: str = get_auth_token()

# --- Worker Management ---
# The name of the Docker Compose service defined for the worker
WORKER_SERVICE_NAME: str = "code-interpreter_worker"

# The name of the internal Docker network workers and the gateway share
# [æ›´æ–°] æ›´æ”¹ä¸ºæ–°çš„éš”ç¦»ç½‘ç»œåç§°
INTERNAL_NETWORK_NAME: str = os.environ.get("INTERNAL_NETWORK_NAME", "code-interpreter_workers_isolated_net")

# The image to use for creating new worker containers.
# This should match the image built for the worker service.
WORKER_IMAGE_NAME: str = "code-interpreter-worker:latest" # Docker compose creates this image name

# --- Pool Sizing ---
# The minimum number of idle workers to keep ready in the pool.
MIN_IDLE_WORKERS: int = 2

# The absolute maximum number of concurrent workers allowed.
MAX_TOTAL_WORKERS: int = 30

# --- Timeout ---
# Time in seconds a worker can be idle (not executing code) before being recycled.
WORKER_IDLE_TIMEOUT: int = 3600  # 1 hour

# How often the background task runs to check for timed-out workers.
RECYCLING_INTERVAL: int = 300  # 5 minutes

```

--- 

`gateway\dto.py`

```python
from enum import StrEnum
from pydantic import BaseModel, Field
import time

class WorkerStatus(StrEnum):
    IDLE = "idle"
    BUSY = "busy"
    CREATING = "creating"
    ERROR = "error"

class Worker(BaseModel):
    """Represents the internal state of a Worker container in the Gateway."""
    container_id: str
    container_name: str
    internal_url: str
    status: WorkerStatus = WorkerStatus.CREATING
    user_uuid: str | None = None
    last_active_timestamp: float = Field(default_factory=time.time)

class ExecuteRequest(BaseModel):
    user_uuid: str
    code: str

class ExecuteResponse(BaseModel):
    result_text: str | None = None
    result_base64: str | None = None

class ReleaseRequest(BaseModel):
    user_uuid: str

class ReleaseResponse(BaseModel):
    status: str
    detail: str

class ErrorDetail(BaseModel):
    detail: str

```

--- 

`gateway\main.py`

```python
import asyncio
from contextlib import asynccontextmanager

import httpx
from fastapi import FastAPI, HTTPException, Depends, Header, Request
from fastapi.middleware.cors import CORSMiddleware
from loguru import logger as l

import config
from dto import (
    ExecuteRequest, ExecuteResponse,
    ReleaseRequest, ReleaseResponse
)
from utils import raise_internal_error
from worker_manager import WorkerManager


@asynccontextmanager
async def lifespan(app: FastAPI):
    # Configure and initialize the WorkerManager
    l.info(f"token: {config.AUTH_TOKEN}")

    await WorkerManager.init(
        worker_image_name=config.WORKER_IMAGE_NAME,
        internal_network_name=config.INTERNAL_NETWORK_NAME,
        min_idle_workers=config.MIN_IDLE_WORKERS,
        max_total_workers=config.MAX_TOTAL_WORKERS,
        worker_idle_timeout=config.WORKER_IDLE_TIMEOUT,
        recycling_interval=config.RECYCLING_INTERVAL,
    )

    # Start the background task
    recycling_task = asyncio.create_task(WorkerManager.recycle_timed_out_workers())
    yield
    # Cleanup on shutdown
    recycling_task.cancel()
    l.info("Shutting down. Cleaning up all worker containers...")
    await WorkerManager.close()


app = FastAPI(title="Code Interpreter Gateway", lifespan=lifespan)

origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰æ–¹æ³• (GET, POST, OPTIONS ç­‰)
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´ (åŒ…æ‹¬ X-Auth-Token)
)

@app.exception_handler(Exception)
async def handle_unexpected_exceptions(request: Request, exc: Exception):
    """
    æ•è·æ‰€æœ‰æœªç»å¤„ç†çš„å¼‚å¸¸ï¼Œé˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚
    """
    # 1. ä¸ºå¼€å‘äººå‘˜è®°å½•è¯¦ç»†çš„ã€åŒ…å«å®Œæ•´å †æ ˆè·Ÿè¸ªçš„é”™è¯¯æ—¥å¿—
    l.exception(
        f"An unhandled exception occurred for request: {request.method} {request.url.path}"
    )

    raise_internal_error()

# --- Security ---
async def verify_token(x_auth_token: str = Header()):
    if x_auth_token != config.AUTH_TOKEN:
        raise HTTPException(status_code=401, detail="Invalid or missing authentication token")

# --- API Endpoints ---
@app.post(
    "/execute",
    dependencies=[Depends(verify_token)],
)
async def execute(request: ExecuteRequest) -> ExecuteResponse:
    worker = await WorkerManager.get_worker_for_user(request.user_uuid)
    if not worker:
        raise HTTPException(status_code=503, detail="No available workers at the moment, please try again later.")

    # Proxy the request to the assigned worker
    try:
        async with httpx.AsyncClient() as client:
            worker_request_body = {"code": request.code}
            response = await client.post(
                f"{worker.internal_url}/execute",
                json=worker_request_body,
                timeout=30.0 # A reasonable timeout for the whole operation
            )
            # Forward the worker's response (both success and error)
            if response.status_code != 200:
                error_detail = response.json().get("detail", "Worker returned an unknown error.")
                raise HTTPException(status_code=response.status_code, detail=error_detail)
            return ExecuteResponse(**response.json())
    except httpx.RequestError as e:
        l.error(f"Failed to proxy request to worker {worker.container_name}: {e}")
        await WorkerManager.release_worker_by_user(request.user_uuid)
        raise HTTPException(status_code=504, detail="Gateway Timeout: Could not connect to the execution worker.")
    except HTTPException as he:
        raise
    except Exception as e:
        l.exception(e)
        await WorkerManager.release_worker_by_user(request.user_uuid)
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post("/release", response_model=ReleaseResponse, dependencies=[Depends(verify_token)])
async def release(request: ReleaseRequest):
    await WorkerManager.release_worker_by_user(request.user_uuid)
    return ReleaseResponse(status="ok", detail=f"Worker for user {request.user_uuid} has been released.")

@app.get("/status")
async def get_status():
    return {
        "total_workers": len(WorkerManager.workers),
        "busy_workers": len(WorkerManager.user_to_worker_map),
        "idle_workers_in_pool": WorkerManager.idle_workers.qsize(),
        "is_initializing": WorkerManager._is_initializing,
    }

```

--- 

`gateway\requirements.txt`

```
fastapi
uvicorn[standard]
loguru
httpx
pydantic
aiodocker

```

--- 

`gateway\utils.py`

```python
from typing import Any, NoReturn, TYPE_CHECKING

from fastapi import HTTPException

from starlette.status import (
    HTTP_400_BAD_REQUEST,
    HTTP_401_UNAUTHORIZED,
    HTTP_403_FORBIDDEN,
    HTTP_404_NOT_FOUND,
    HTTP_409_CONFLICT,
    HTTP_429_TOO_MANY_REQUESTS,
    HTTP_500_INTERNAL_SERVER_ERROR,
    HTTP_501_NOT_IMPLEMENTED,
    HTTP_503_SERVICE_UNAVAILABLE,
    HTTP_504_GATEWAY_TIMEOUT, HTTP_402_PAYMENT_REQUIRED,
)

# --- Request and Response Helpers ---

def ensure_request_param(to_check: Any, detail: str) -> None:
    """
    Ensures a parameter exists. If not, raises a 400 Bad Request.
    This function returns None if the check passes.
    """
    if not to_check:
        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=detail)

def raise_bad_request(detail: str = '') -> NoReturn:
    """Raises an HTTP 400 Bad Request exception."""
    raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=detail)

def raise_not_found(detail: str) -> NoReturn:
    """Raises an HTTP 404 Not Found exception."""
    raise HTTPException(status_code=HTTP_404_NOT_FOUND, detail=detail)

def raise_internal_error(detail: str = "æœåŠ¡å™¨å‡ºç°æ•…éšœï¼Œè¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜") -> NoReturn:
    """Raises an HTTP 500 Internal Server Error exception."""
    raise HTTPException(status_code=HTTP_500_INTERNAL_SERVER_ERROR, detail=detail)

def raise_forbidden(detail: str) -> NoReturn:
    """Raises an HTTP 403 Forbidden exception."""
    raise HTTPException(status_code=HTTP_403_FORBIDDEN, detail=detail)

def raise_unauthorized(detail: str) -> NoReturn:
    """Raises an HTTP 401 Unauthorized exception."""
    raise HTTPException(status_code=HTTP_401_UNAUTHORIZED, detail=detail)

def raise_conflict(detail: str) -> NoReturn:
    """Raises an HTTP 409 Conflict exception."""
    raise HTTPException(status_code=HTTP_409_CONFLICT, detail=detail)

def raise_too_many_requests(detail: str) -> NoReturn:
    """Raises an HTTP 429 Too Many Requests exception."""
    raise HTTPException(status_code=HTTP_429_TOO_MANY_REQUESTS, detail=detail)

def raise_not_implemented(detail: str = "å°šæœªæ”¯æŒè¿™ç§æ–¹æ³•") -> NoReturn:
    """Raises an HTTP 501 Not Implemented exception."""
    raise HTTPException(status_code=HTTP_501_NOT_IMPLEMENTED, detail=detail)

def raise_service_unavailable(detail: str) -> NoReturn:
    """Raises an HTTP 503 Service Unavailable exception."""
    raise HTTPException(status_code=HTTP_503_SERVICE_UNAVAILABLE, detail=detail)

def raise_gateway_timeout(detail: str) -> NoReturn:
    """Raises an HTTP 504 Gateway Timeout exception."""
    raise HTTPException(status_code=HTTP_504_GATEWAY_TIMEOUT, detail=detail)

def raise_insufficient_quota(detail: str = "ç§¯åˆ†ä¸è¶³ï¼Œè¯·å……å€¼") -> NoReturn:
    raise HTTPException(status_code=HTTP_402_PAYMENT_REQUIRED, detail=detail)

# --- End of Request and Response Helpers ---

```

--- 

`gateway\worker_manager.py`

```python
import asyncio
import time
import uuid

import httpx
from aiodocker.containers import DockerContainer
from aiodocker.docker import Docker
from aiodocker.exceptions import DockerError
from fastapi import HTTPException
from loguru import logger as l

from dto import Worker, WorkerStatus


class WorkerManager:
    """
    Manages the lifecycle of Docker-based worker containers.

    This class is implemented as a Singleton using only class-level variables
    and methods. It handles the creation, assignment, and destruction of
    workers, maintaining a pool of idle workers to handle user requests
    promptly.
    """
    # --- Configuration variables ---
    # These must be set by calling the `init` method before use.
    WORKER_IMAGE_NAME: str
    INTERNAL_NETWORK_NAME: str
    MIN_IDLE_WORKERS: int
    MAX_TOTAL_WORKERS: int
    WORKER_IDLE_TIMEOUT: int
    RECYCLING_INTERVAL: int

    # --- Internal state ---
    docker: Docker = Docker()
    workers: dict[str, Worker] = {}  # container_id -> Worker
    user_to_worker_map: dict[str, str] = {}  # user_uuid -> container_id
    idle_workers: asyncio.Queue[Worker] = asyncio.Queue()
    _lock: asyncio.Lock = asyncio.Lock()
    _is_initializing: bool = True

    @classmethod
    async def init(
        cls,
        worker_image_name: str,
        internal_network_name: str,
        min_idle_workers: int,
        max_total_workers: int,
        worker_idle_timeout: int,
        recycling_interval: int,
    ) -> None:
        """
        Injects configuration and initializes the worker pool.

        Cleans up any stale worker containers from previous runs and
        pre-warms the pool by creating a minimum number of idle workers.
        """
        # 1. Configure the manager
        cls.WORKER_IMAGE_NAME = worker_image_name
        cls.INTERNAL_NETWORK_NAME = internal_network_name
        cls.MIN_IDLE_WORKERS = min_idle_workers
        cls.MAX_TOTAL_WORKERS = max_total_workers
        cls.WORKER_IDLE_TIMEOUT = worker_idle_timeout
        cls.RECYCLING_INTERVAL = recycling_interval

        # 2. Initialize the pool
        l.info("Initializing worker pool...")
        await cls._cleanup_stale_workers()
        await cls._replenish_idle_pool()
        cls._is_initializing = False
        l.info(f"Worker pool initialized. Idle workers: {cls.idle_workers.qsize()}")

    @classmethod
    async def close(cls) -> None:
        """Closes the Docker client connection."""
        await cls.docker.close()

    @classmethod
    async def _cleanup_stale_workers(cls) -> None:
        """Finds and removes any dangling worker containers managed by this gateway."""
        try:
            old_workers: list[DockerContainer] = await cls.docker.containers.list(
                filters={"label": [f"managed-by=code-interpreter-gateway"]},
            )
            if not old_workers:
                return

            l.warning(f"Found {len(old_workers)} stale worker containers. Cleaning up...")
            cleanup_tasks = [container.delete(force=True) for container in old_workers]
            await asyncio.gather(*cleanup_tasks, return_exceptions=True)
            l.info("Stale worker cleanup complete.")
        except DockerError as e:
            l.error(f"Error during stale worker cleanup: {e}")

    @classmethod
    async def _create_new_worker(cls) -> Worker:
        """
        Creates, starts, and health-checks a single new worker container.

        :return: A healthy Worker object or None if creation fails.
        """
        container_name = f"code-worker-{uuid.uuid4().hex[:12]}"
        try:
            l.info(f"Creating new worker container: {container_name}")
            container: DockerContainer = await cls.docker.containers.create_or_replace(
                config={
                    'Image': cls.WORKER_IMAGE_NAME,
                    'HostConfig': {
                        'NetworkMode': cls.INTERNAL_NETWORK_NAME,
                    },
                    'Labels': {'managed-by': "code-interpreter-gateway"},
                },
                name=container_name,
            )
            await container.start()

            worker = Worker(
                container_id=container.id,
                container_name=container_name,
                internal_url=f"http://{container_name}:8000",
                status=WorkerStatus.IDLE,
            )

            is_healthy = await cls._is_worker_healthy(worker)
            if not is_healthy:
                l.error(f"Newly created worker {container_name} is unhealthy. Removing.")
                await cls._destroy_worker(worker)
                raise RuntimeError("Worker failed health check after creation.")

            l.success(f"Worker {container_name} created and healthy.")
            return worker
        except DockerError as e:
            msg = f"Failed to create container {container_name}: {e}"
            l.error(msg)
            raise RuntimeError(msg)

    @classmethod
    async def _is_worker_healthy(cls, worker: Worker, timeout: int = 30) -> bool:
        """
        Performs a health check on a worker by polling its /health endpoint.

        :param worker: The worker to check.
        :param timeout: The maximum time in seconds to wait for the worker to become healthy.
        :return: True if the worker is healthy, False otherwise.
        """
        start_time = time.time()
        async with httpx.AsyncClient() as client:
            while time.time() - start_time < timeout:
                try:
                    response = await client.get(f"{worker.internal_url}/health", timeout=2.0)
                    if response.status_code == 200:
                        return True
                except httpx.RequestError:
                    await asyncio.sleep(0.1)
            return False

    @classmethod
    async def _destroy_worker(cls, worker: Worker) -> None:
        """
        Stops and removes a worker's Docker container and cleans up internal state.

        :param worker: The worker to destroy.
        """
        l.warning(f"Destroying worker: {worker.container_name}")
        try:
            container: DockerContainer = cls.docker.containers.container(worker.container_id)
            await container.delete(force=True)
        except DockerError as e:
            if e.status == 404:
                l.warning(f"Worker {worker.container_name} not found.")
            else:
                msg = f"Error deleting container {worker.container_name}: {e}"
                l.error(msg)
                raise RuntimeError(msg)
        finally:
            # Clean up internal state
            cls.workers.pop(worker.container_id, None)
            if worker.user_uuid and worker.user_uuid in cls.user_to_worker_map:
                cls.user_to_worker_map.pop(worker.user_uuid, None)

    @classmethod
    async def get_worker_for_user(cls, user_uuid: str) -> Worker:
        """
        Gets a worker for a given user.

        Retrieves an existing worker, an idle worker from the pool, or creates
        a new one.

        :param user_uuid: The UUID of the user requesting a worker.
        :return: An available Worker instance.
        :raises HTTPException: If the pool is initializing or no worker is available.
        """
        async with cls._lock:
            if cls._is_initializing:
                raise HTTPException(
                    status_code=503,
                    detail="Worker pool is initializing. Please try again shortly.",
                )

            # Case 1: User already has an active worker
            if user_uuid in cls.user_to_worker_map:
                container_id = cls.user_to_worker_map[user_uuid]
                worker = cls.workers[container_id]
                worker.last_active_timestamp = time.time()
                l.info(f"Found existing worker {worker.container_name} for user {user_uuid}")
                return worker

            # Case 2: Get an idle worker from the pool
            if not cls.idle_workers.empty():
                worker = await cls.idle_workers.get()
                cls._bind_worker_to_user(worker, user_uuid)
                l.info(f"Assigned idle worker {worker.container_name} to user {user_uuid}")
                return worker

            # Case 3: Create a new worker if under the configured maximum limit
            if len(cls.workers) < cls.MAX_TOTAL_WORKERS:
                l.info("No idle workers available. Attempting to create a new one.")
                worker = await cls._create_new_worker()
                if worker:
                    cls.workers[worker.container_id] = worker
                    cls._bind_worker_to_user(worker, user_uuid)
                    l.info(
                        f"Assigned newly created worker {worker.container_name} to user {user_uuid}"
                    )
                    return worker

            # Case 4: Max limit reached, no workers available
            raise HTTPException(status_code=503, detail="No available workers. Please try again later.")

    @classmethod
    def _bind_worker_to_user(cls, worker: Worker, user_uuid: str) -> None:
        """
        Assigns a worker to a user and updates its state.

        :param worker: The worker to be assigned.
        :param user_uuid: The user's UUID.
        """
        worker.status = WorkerStatus.BUSY
        worker.user_uuid = user_uuid
        worker.last_active_timestamp = time.time()
        cls.user_to_worker_map[user_uuid] = worker.container_id

    @classmethod
    async def release_worker_by_user(cls, user_uuid: str) -> None:
        """
        Releases a worker previously assigned to a user.

        This method destroys the worker container and triggers pool replenishment.

        :param user_uuid: The UUID of the user releasing the worker.
        """
        async with cls._lock:
            if user_uuid not in cls.user_to_worker_map:
                return

            container_id = cls.user_to_worker_map.pop(user_uuid)
            worker = cls.workers.pop(container_id)
            l.info(f"User {user_uuid} released worker {worker.container_name}. Destroying...")
            await cls._destroy_worker(worker)
            await cls._replenish_idle_pool()

    @classmethod
    async def _replenish_idle_pool(cls) -> None:
        """
        Creates new workers to meet the minimum idle worker requirement.

        This function should always be called within a lock to ensure thread safety.
        """
        needed_count = cls.MIN_IDLE_WORKERS - cls.idle_workers.qsize()
        available_slots = cls.MAX_TOTAL_WORKERS - len(cls.workers)

        creation_count = min(needed_count, available_slots)
        if creation_count <= 0:
            return

        l.info(f"Replenishing idle pool. Need to create {creation_count} worker(s).")
        tasks = [cls._create_new_worker() for _ in range(creation_count)]
        new_workers = await asyncio.gather(*tasks)

        for worker in new_workers:
            if worker:
                cls.workers[worker.container_id] = worker
                await cls.idle_workers.put(worker)

    @classmethod
    async def recycle_timed_out_workers(cls) -> None:
        """
        Periodically checks for and recycles workers that have been idle for too long.

        This method is designed to be run as a continuous background task.
        """
        while True:
            await asyncio.sleep(cls.RECYCLING_INTERVAL)
            async with cls._lock:
                l.info("Running background task to recycle timed-out workers...")
                now = time.time()
                timed_out_users: list[str] = []
                for user_uuid, container_id in cls.user_to_worker_map.items():
                    worker = cls.workers.get(container_id)
                    if worker and (now - worker.last_active_timestamp > cls.WORKER_IDLE_TIMEOUT):
                        timed_out_users.append(user_uuid)

                if timed_out_users:
                    l.warning(f"Found {len(timed_out_users)} timed-out workers to recycle.")
                    for user_uuid in timed_out_users:
                        container_id = cls.user_to_worker_map.pop(user_uuid)
                        worker = cls.workers.pop(container_id)
                        await cls._destroy_worker(worker)

                    await cls._replenish_idle_pool()
                else:
                    l.info("No timed-out workers found.")

```

--- 

`start.ps1`

```
# start.ps1

# è®¾ç½®è„šæœ¬åœ¨é‡åˆ°é”™è¯¯æ—¶ç«‹å³åœæ­¢
$ErrorActionPreference = "Stop"

Write-Host "ğŸš€ [Step 1/2] Starting the Code Interpreter environment..." -ForegroundColor Green
# ä½¿ç”¨ --build ç¡®ä¿é•œåƒæ€»æ˜¯æœ€æ–°çš„
# ä½¿ç”¨ -d åœ¨åå°è¿è¡Œ
docker-compose up --build -d

# æ£€æŸ¥ä¸Šä¸€ä¸ªå‘½ä»¤æ˜¯å¦æˆåŠŸ
if ($LASTEXITCODE -ne 0) {
    Write-Host "âŒ docker-compose up failed. Please check the logs." -ForegroundColor Red
    exit 1
}

Write-Host "âœ… Environment started. Gateway is running." -ForegroundColor Green
Write-Host "ğŸ§¹ [Step 2/2] Cleaning up the temporary builder container..." -ForegroundColor Cyan

# æŸ¥æ‰¾åä¸º code-interpreter_worker_builder çš„å®¹å™¨
$builderId = docker ps -a -q --filter "name=code-interpreter_worker_builder"

if ($builderId) {
    Write-Host "   -> Found builder container. Removing it..."
    docker rm $builderId | Out-Null
    Write-Host "   -> Builder container successfully removed." -ForegroundColor Green
} else {
    Write-Host "   -> No temporary builder container found to clean up. Skipping." -ForegroundColor Yellow
}

Write-Host "ğŸ‰ Startup complete. The system is ready."

```

--- 

`stop.ps1`

```
# stop.ps1

# è®¾ç½®è„šæœ¬åœ¨é‡åˆ°é”™è¯¯æ—¶ç»§ç»­æ‰§è¡Œï¼Œå› ä¸ºæˆ‘ä»¬é¢„æœŸæŸäº›å‘½ä»¤å¯èƒ½ä¼šâ€œå¤±è´¥â€
$ErrorActionPreference = "SilentlyContinue"

Write-Host "ğŸ›‘ Initiating shutdown sequence for the Code Interpreter environment..." -ForegroundColor Yellow

Write-Host "ğŸ¤š [Step 1/3] Stopping the gateway container to prevent new workers..." -ForegroundColor Cyan
# ç¬¬ä¸€æ¬¡ down ä¼šåœæ­¢å¹¶ç§»é™¤ gatewayã€‚ç½‘ç»œåˆ é™¤å¤±è´¥æ˜¯æ­£å¸¸çš„ã€‚
docker-compose down
Write-Host "   -> Gateway stopped."

Write-Host "ğŸ”¥ [Step 2/3] Finding and forcibly removing all dynamically created workers..." -ForegroundColor Cyan
$workerIds = docker ps -a -q --filter "label=managed-by=code-interpreter-gateway"

if ($workerIds) {
    Write-Host "   -> Found running worker containers. Removing them now..."
    docker rm -f $workerIds | Out-Null
    Write-Host "   -> All dynamic workers have been removed." -ForegroundColor Green
} else {
    Write-Host "   -> No dynamically created workers found." -ForegroundColor Yellow
}

Write-Host "ğŸ§¹ [Step 3/3] Final cleanup to remove the network..." -ForegroundColor Cyan
# å› ä¸º worker å·²ç»è¢«æ¸…ç†ï¼Œè¿™æ¬¡ down å°†æˆåŠŸç§»é™¤ç½‘ç»œ
docker-compose down
Write-Host "   -> Network and remaining resources cleaned up."

Write-Host "âœ… Shutdown and cleanup complete." -ForegroundColor Green


```

--- 

`test.html`

```
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Code Interpreter API Test Client</title>
    <style>
        :root {
            --bg-color: #f8f9fa;
            --text-color: #212529;
            --primary-color: #0d6efd;
            --border-color: #dee2e6;
            --pre-bg-color: #e9ecef;
            --error-color: #dc3545;
            --success-color: #198754;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .container {
            width: 100%;
            max-width: 800px;
            background: #fff;
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        }
        h1, h2 {
            text-align: center;
            color: #333;
        }
        .form-group {
            margin-bottom: 15px;
        }
        label {
            display: block;
            font-weight: 600;
            margin-bottom: 5px;
        }
        input[type="text"], textarea {
            width: 100%;
            padding: 10px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            box-sizing: border-box;
            font-size: 16px;
        }
        textarea {
            height: 200px;
            font-family: Consolas, "Courier New", monospace;
            resize: vertical;
        }
        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 15px;
        }
        button {
            padding: 10px 15px;
            border: none;
            border-radius: 4px;
            background-color: var(--primary-color);
            color: white;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.2s;
            flex-grow: 1;
        }
        button:hover {
            background-color: #0b5ed7;
        }
        button:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        button.secondary {
            background-color: #6c757d;
        }
        button.secondary:hover {
            background-color: #5c636a;
        }
        #session-controls {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        #session-controls input {
            flex-grow: 1;
        }
        #output-log {
            margin-top: 25px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 15px;
            height: 400px;
            overflow-y: auto;
            background-color: var(--bg-color);
        }
        .log-entry {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px dashed var(--border-color);
        }
        .log-entry:last-child {
            border-bottom: none;
        }
        pre {
            background-color: var(--pre-bg-color);
            padding: 10px;
            border-radius: 4px;
            white-space: pre-wrap;
            word-wrap: break-word;
            margin: 5px 0;
        }
        .log-input pre {
            background-color: #dbeafe;
        }
        .log-output pre, .log-output img {
            background-color: #e9ecef;
        }
        .log-error pre {
            background-color: #f8d7da;
            color: var(--error-color);
        }
        .log-status {
            font-style: italic;
            color: #6c757d;
        }
        img.result-image {
            max-width: 100%;
            height: auto;
            border: 1px solid var(--border-color);
            margin-top: 10px;
            display: block;
        }
    </style>
</head>
<body>

<div class="container">
    <h1>Code Interpreter Test Client</h1>

    <h2>1. Configuration</h2>
    <div class="form-group">
        <label for="gateway-url">Gateway URL</label>
        <input type="text" id="gateway-url" value="http://127.0.0.1:3874">
    </div>
    <div class="form-group">
        <label for="auth-token">Auth Token (X-Auth-Token)</label>
        <input type="text" id="auth-token" placeholder="Paste your token here">
    </div>
    <div class="form-group">
        <label for="user-uuid">Current Session UUID</label>
        <div id="session-controls">
            <input type="text" id="user-uuid" readonly>
            <button id="regenerate-uuid" class="secondary" title="Start a new session">New Session</button>
        </div>
    </div>

    <h2>2. Code Execution</h2>
    <div class="form-group">
        <label for="code-input">Python Code</label>
        <textarea id="code-input" placeholder="a = 10&#10;b = 20&#10;print(f'The sum is {a + b}')"></textarea>
    </div>
    <div class="button-group">
        <button id="run-button">Run Code</button>
        <button id="release-button" class="secondary">Release Session</button>
    </div>

    <h2>3. Session Log</h2>
    <div id="output-log">
        <div class="log-status">Ready to execute code...</div>
    </div>
</div>

<script>
    // --- DOM Elements ---
    const gatewayUrlInput = document.getElementById('gateway-url');
    const authTokenInput = document.getElementById('auth-token');
    const userUuidInput = document.getElementById('user-uuid');
    const codeInput = document.getElementById('code-input');
    const runButton = document.getElementById('run-button');
    const releaseButton = document.getElementById('release-button');
    const regenerateUuidButton = document.getElementById('regenerate-uuid');
    const outputLog = document.getElementById('output-log');

    // --- Functions ---

    /** Generates a v4 UUID */
    function generateUUID() {
        return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>
            (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)
        );
    }

    /** Clears the log and adds a message */
    function clearLog(message) {
        outputLog.innerHTML = `<div class="log-status">${message}</div>`;
    }

    /** Appends a new entry to the log */
    function appendToLog(entry) {
        const isScrolledToBottom = outputLog.scrollHeight - outputLog.clientHeight <= outputLog.scrollTop + 1;

        const firstEntry = outputLog.querySelector('.log-status');
        if (firstEntry) {
            outputLog.innerHTML = '';
        }
        outputLog.appendChild(entry);

        if (isScrolledToBottom) {
            outputLog.scrollTop = outputLog.scrollHeight;
        }
    }

    /** Creates a log entry element */
    function createLogEntry(code, resultElement) {
        const entryDiv = document.createElement('div');
        entryDiv.className = 'log-entry';

        const inputHeader = document.createElement('strong');
        inputHeader.textContent = 'Input Code:';
        const inputPre = document.createElement('pre');
        inputPre.textContent = code;
        const inputDiv = document.createElement('div');
        inputDiv.className = 'log-input';
        inputDiv.append(inputHeader, inputPre);

        const outputHeader = document.createElement('strong');
        outputHeader.textContent = 'Result:';
        const outputDiv = document.createElement('div');
        // ã€ä¿®æ­£ã€‘æ ¹æ® resultElement æ˜¯å¦æœ‰ 'log-error' class æ¥å†³å®šçˆ¶ div çš„ class
        outputDiv.className = resultElement.classList.contains('log-error') ? 'log-error' : 'log-output';
        outputDiv.append(outputHeader, resultElement);

        entryDiv.append(inputDiv, outputDiv);
        return entryDiv;
    }

    /** Handles code execution */
    async function handleExecute() {
        // ã€ä¿®æ­£ã€‘ä¸ºæ‰€æœ‰è¾“å…¥éƒ½æ·»åŠ  .trim() å¢åŠ å¥å£®æ€§
        const gatewayUrl = gatewayUrlInput.value.trim();
        const authToken = authTokenInput.value.trim();
        const userUuid = userUuidInput.value.trim();
        const code = codeInput.value.trim();

        if (!gatewayUrl || !authToken || !userUuid || !code) {
            alert('Please fill in all fields: Gateway URL, Auth Token, and Code.');
            return;
        }

        runButton.disabled = true;
        runButton.textContent = 'Executing...';

        let resultElement;
        try {
            const response = await fetch(`${gatewayUrl}/execute`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'X-Auth-Token': authToken
                },
                body: JSON.stringify({
                    user_uuid: userUuid,
                    code: code
                })
            });

            const data = await response.json();

            if (!response.ok) {
                resultElement = document.createElement('pre');
                // ã€ä¿®æ­£ã€‘ç›´æ¥ç»™ resultElement æœ¬èº«æ·»åŠ  classï¼Œè€Œä¸æ˜¯ç»™å®ƒä¸å­˜åœ¨çš„ parentElement
                resultElement.classList.add('log-error');
                resultElement.textContent = `Error ${response.status}: ${data.detail || JSON.stringify(data)}`;
            } else {
                if (data.result_base64) {
                    resultElement = document.createElement('img');
                    resultElement.className = 'result-image';
                    resultElement.src = `data:image/png;base64,${data.result_base64}`;
                } else {
                    resultElement = document.createElement('pre');
                    resultElement.textContent = data.result_text ?? '(No text output)';
                }
            }
        } catch (error) {
            resultElement = document.createElement('pre');
            // ã€ä¿®æ­£ã€‘åŒæ ·ï¼Œç›´æ¥ç»™ resultElement æœ¬èº«æ·»åŠ  class
            resultElement.classList.add('log-error');
            resultElement.textContent = `Network or fetch error: ${error.message}`;
        } finally {
            runButton.disabled = false;
            runButton.textContent = 'Run Code';
            if (resultElement) { // ç¡®ä¿ resultElement å­˜åœ¨
                const logEntry = createLogEntry(code, resultElement);
                appendToLog(logEntry);
            }
        }
    }

    /** Handles session release */
    async function handleRelease() {
        const gatewayUrl = gatewayUrlInput.value.trim();
        const authToken = authTokenInput.value.trim();
        const userUuid = userUuidInput.value.trim();

        if (!gatewayUrl || !authToken || !userUuid) {
            alert('Please provide Gateway URL and Auth Token.');
            return;
        }

        releaseButton.disabled = true;
        releaseButton.textContent = 'Releasing...';
        try {
            const response = await fetch(`${gatewayUrl}/release`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'X-Auth-Token': authToken
                },
                body: JSON.stringify({ user_uuid: userUuid })
            });

            const data = await response.json();
            const message = response.ok ? `Success: ${data.detail}` : `Error: ${data.detail}`;
            clearLog(`Session ${userUuid} released. ${message}. Start a new session by clicking 'New Session'.`);

        } catch (error) {
            alert(`Failed to release session: ${error.message}`);
        } finally {
            releaseButton.disabled = false;
            releaseButton.textContent = 'Release Session';
        }
    }

    /** Starts a new session */
    function startNewSession() {
        userUuidInput.value = generateUUID();
        clearLog(`New session started with UUID: ${userUuidInput.value}. Ready to execute code...`);
    }

    // --- Event Listeners ---
    document.addEventListener('DOMContentLoaded', startNewSession);
    runButton.addEventListener('click', handleExecute);
    releaseButton.addEventListener('click', handleRelease);
    regenerateUuidButton.addEventListener('click', startNewSession);

</script>
</body>
</html>

```

--- 

`worker\Dockerfile`

```
# worker/Dockerfile

FROM python:3.12-slim-bookworm

LABEL maintainer="Foxerine"
LABEL description="A self-contained, secure, stateful Python code interpreter WORKER."

ENV LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    PYTHONUNBUFFERED=1

# [æ–°å¢] åˆ›å»ºæ²™ç®±ç›®å½•ï¼Œè¿™å°†æ˜¯ä»£ç æ‰§è¡Œçš„é»˜è®¤å·¥ä½œåŒº
RUN mkdir /sandbox

# Install system dependencies
RUN apt-get update && \
    apt-get install -y --no-install-recommends supervisor tini fontconfig libgl1-mesa-glx libglib2.0-0 curl && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Install font
COPY ./assets/simhei.ttf /usr/share/fonts/truetype/
RUN fc-cache -fv

# Install Python dependencies
WORKDIR /worker
# [æ›´æ–°] å°† PYTHONPATH è®¾ç½®ä¸º /workerï¼Œä»¥ä¾¿åœ¨ /sandbox ä¸­ä¹Ÿèƒ½å¯¼å…¥åº”ç”¨ä»£ç 
ENV PYTHONPATH=/worker
COPY ./requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt && rm /tmp/requirements.txt

RUN ipython kernel install --name "python3" --user

# Copy application code & configs
COPY . /worker
COPY ./supervisor/supervisord.conf /etc/supervisor/supervisord.conf

# [æ›´æ–°] å°†æœ€ç»ˆçš„å·¥ä½œç›®å½•åˆ‡æ¢åˆ°æ²™ç®±
WORKDIR /sandbox

EXPOSE 8000
ENTRYPOINT ["/usr/bin/tini", "--", "/usr/bin/supervisord", "-c", "/etc/supervisor/supervisord.conf"]

```

--- 

`worker\dto.py`

```python
"""Data Transfer Objects (DTOs) for the Python Code Interpreter API."""
from typing import Literal

from pydantic import BaseModel, Field


class ExecuteRequest(BaseModel):
    """Defines the structure for a Python code execution request."""
    code: str


class ExecuteResponse(BaseModel):
    """Defines the structure for a code execution response."""
    result_text: str | None = None
    result_base64: str | None = None


class HealthDetail(BaseModel):
    """Describes the health status of a single internal service."""
    status: str
    detail: str


class HealthStatus(BaseModel):
    """Describes the overall health of the container."""
    status: str
    services: dict[str, HealthDetail]

class ExecutionResult(BaseModel):
    """ä»£ç æ‰§è¡Œç»“æœçš„ DTO"""
    status: Literal["ok", "error", "timeout"]
    type: Literal["text", "image_png_base64", "connection_error", "execution_error", "timeout_error", "processing_error"]
    value: str | None = None

```

--- 

`worker\kernel_manager.py`

```python
# worker/kernel_manager.py

"""
Manages the lifecycle and interaction with a stateful Jupyter Kernel.
This module is fully compliant with the websockets library's best practices.
"""
import asyncio
import json
import time
from uuid import uuid4
from xmlrpc.client import ServerProxy

import httpx
from loguru import logger as l
from websockets.asyncio.client import connect, ClientConnection
from websockets.exceptions import ConnectionClosed, WebSocketException
from websockets.protocol import OPEN

from dto import ExecutionResult


class JupyterKernelManager:
    """A static manager for a persistent Jupyter Kernel."""
    # --- Constants ---
    JUPYTER_HOST: str = "127.0.0.1:8888"
    JUPYTER_API_URL: str = f"http://{JUPYTER_HOST}"
    JUPYTER_WS_URL: str = f"ws://{JUPYTER_HOST}"
    EXECUTION_TIMEOUT: float = 10.0

    _MATPLOTLIB_FONT_PREP_CODE: str = (
        "import matplotlib\n"
        "matplotlib.rcParams['font.family'] = ['SimHei']\n"
        "matplotlib.rcParams['axes.unicode_minus'] = False\n"
    )

    # --- State ---
    _kernel_id: str | None = None
    _ws_connection: ClientConnection | None = None
    _lock = asyncio.Lock()
    _supervisor = ServerProxy('http://127.0.0.1:9001/RPC2')

    @classmethod
    async def start_kernel(cls) -> None:
        """å¯åŠ¨å¹¶è¿æ¥åˆ°ä¸€ä¸ªæ–°çš„ Jupyter Kernel å®ä¾‹ï¼Œå¸¦æœ‰é‡è¯•æœºåˆ¶ä»¥æé«˜å¯åŠ¨ç¨³å®šæ€§ã€‚"""
        if cls._kernel_id:
            l.warning("Kernel å·²ç»å¯åŠ¨ã€‚")
            return

        l.info("æ­£åœ¨å°è¯•å¯åŠ¨å¹¶è¿æ¥åˆ°æ–°çš„ Jupyter Kernel...")
        max_retries = 10
        retry_delay = 1.0  # seconds

        for attempt in range(max_retries):
            try:
                async with httpx.AsyncClient(timeout=5.0) as client:
                    response = await client.post(
                        url=f'{cls.JUPYTER_API_URL}/api/kernels',
                        json={'name': "python"},
                        headers={'Content-Type': 'application/json'}
                    )
                    response.raise_for_status()
                    kernel_data = response.json()
                    cls._kernel_id = kernel_data['id']
                    l.success(f"ğŸš€ Jupyter Kernel å·²æˆåŠŸåˆ›å»º, ID: {cls._kernel_id}")
                    await cls._establish_websocket_connection()

                    l.info("æ­£åœ¨åˆå§‹åŒ– Kernel ç¯å¢ƒ...")
                    init_result = await cls.execute_code(cls._MATPLOTLIB_FONT_PREP_CODE, is_initialization=True)
                    if init_result.status != "ok":
                        l.error(f"ğŸ”¥ Kernel ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥: {init_result.value}")
                        await cls._shutdown_kernel()
                        raise RuntimeError("Kernel ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ã€‚")
                    l.success("âœ… Kernel ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸã€‚")
                    return
            except httpx.RequestError as e:
                l.warning(f"æ— æ³•è¿æ¥åˆ° Jupyter Server (å°è¯• {attempt + 1}/{max_retries}): {e}ã€‚å°†åœ¨ {retry_delay} ç§’åé‡è¯•...")
                await asyncio.sleep(retry_delay)
            except Exception:
                await cls._shutdown_kernel()
                raise

        l.error(f"ğŸ”¥ å¯åŠ¨ Jupyter Kernel å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ã€‚")
        raise RuntimeError("æ— æ³•è¿æ¥åˆ° Jupyter Serverã€‚è¯·æ£€æŸ¥ Jupyter æœåŠ¡çš„æ—¥å¿—ã€‚")

    @classmethod
    async def _shutdown_kernel(cls):
        """å…³é—­å¹¶æ¸…ç†å½“å‰çš„ kernelã€‚"""
        if not cls._kernel_id:
            return
        kernel_id = cls._kernel_id
        cls._kernel_id = None
        l.warning(f"æ­£åœ¨å…³é—­ Kernel {kernel_id}...")
        try:
            if cls._ws_connection and cls._ws_connection.state is OPEN:
                await cls._ws_connection.close()
            cls._ws_connection = None

            async with httpx.AsyncClient(timeout=5.0) as client:
                await client.delete(f'{cls.JUPYTER_API_URL}/api/kernels/{kernel_id}')
            l.info(f"Kernel {kernel_id} å·²æˆåŠŸå…³é—­ã€‚")
        except httpx.RequestError as e:
            l.warning(f"å…³é—­ kernel {kernel_id} æ—¶å‡ºé”™: {e}")
        except Exception as e:
            l.error(f"å…³é—­ kernel {kernel_id} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")

    @classmethod
    async def _establish_websocket_connection(cls) -> None:
        """å»ºç«‹åˆ° Kernel çš„ WebSocket è¿æ¥"""
        if cls._ws_connection and cls._ws_connection.state is OPEN:
            await cls._ws_connection.close()
        try:
            cls._ws_connection = await connect(
                uri=f'{cls.JUPYTER_WS_URL}/api/kernels/{cls._kernel_id}/channels'
            )
            l.info("ğŸ”Œ å·²å»ºç«‹åˆ° Kernel çš„ WebSocket è¿æ¥ã€‚")
        except WebSocketException as e:
            l.error(f"ğŸ”¥ å»ºç«‹ WebSocket è¿æ¥å¤±è´¥: {e}")
            cls._ws_connection = None
            raise

    @classmethod
    async def is_healthy(cls) -> bool:
        """æ£€æŸ¥ WebSocket è¿æ¥æ˜¯å¦å¥åº·"""
        if cls._ws_connection is None or cls._ws_connection.state is not OPEN:
            return False
        try:
            await asyncio.wait_for(cls._ws_connection.ping(), timeout=2.0)
            return True
        except (asyncio.TimeoutError, ConnectionClosed, WebSocketException):
            return False

    @classmethod
    async def reset_kernel(cls) -> bool:
        """é€šè¿‡ Supervisor é‡å¯ Kernel è¿›ç¨‹æ¥é‡ç½®å®ƒ"""
        l.warning("ğŸš¨ æ­£åœ¨é‡ç½® Jupyter Kernel...")
        async with cls._lock:
            process_name = 'jupyter_kernel'
            try:
                cls._supervisor.supervisor.stopProcess(process_name)
                l.info(f"ğŸ›‘ {process_name} è¿›ç¨‹å·²åœæ­¢ã€‚")
                for _ in range(10): # ç­‰å¾…æœ€å¤š10ç§’
                    await asyncio.sleep(1)
                    state_info = cls._supervisor.supervisor.getProcessInfo(process_name)
                    if state_info['state'] == 20:  # RUNNING
                        l.info(f"âœ… {process_name} è¿›ç¨‹å·²ç”± Supervisor é‡å¯ã€‚")
                        # æ¸…ç†æ—§çŠ¶æ€å¹¶é‡æ–°åˆå§‹åŒ–
                        cls._kernel_id = None
                        if cls._ws_connection:
                            await cls._ws_connection.close()
                        cls._ws_connection = None
                        await cls.start_kernel()
                        return True
                l.error(f"ğŸ”¥ {process_name} æœªèƒ½åœ¨æ—¶é™å†…é‡å¯ã€‚")
                return False
            except Exception as e:
                l.error(f"ğŸ”¥ Kernel é‡ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                return False


    @classmethod
    async def execute_code(cls, code: str, is_initialization: bool = False) -> ExecutionResult:
        """åœ¨ Kernel ä¸­æ‰§è¡Œä»£ç å¹¶è¿”å›ç»“æœ"""
        if not is_initialization:
            code_preview = (code[:97] + '...' if len(code) > 100 else code).replace('\n', ' ')
            l.info(f"â–¶ï¸  å‡†å¤‡æ‰§è¡Œä»£ç : {code_preview.strip()}")
            start_time = time.monotonic()

        escaped_code = json.dumps(code)[1:-1]

        async with cls._lock:
            if not await cls.is_healthy():
                l.warning("WebSocket è¿æ¥ä¸å¥åº·ï¼Œæ­£åœ¨å°è¯•é‡è¿...")
                try:
                    await cls._establish_websocket_connection()
                except WebSocketException:
                    return ExecutionResult(status="error", type='connection_error', value="æ‰§è¡Œå¼•æ“è¿æ¥ä¸¢å¤±ã€‚")

            assert cls._ws_connection is not None
            msg_id = uuid4().hex
            execute_request = f'''
            {{
                "header": {{
                    "msg_id": "{msg_id}", "username": "api", "session": "{uuid4().hex}",
                    "msg_type": "execute_request", "version": "5.3"
                }},
                "parent_header": {{}}, "metadata": {{}},
                "content": {{
                    "code": "{escaped_code}", "silent": false, "store_history": false,
                    "user_expressions": {{}}, "allow_stdin": false
                }}, "buffers": [], "channel": "shell"
            }}
            '''
            try:
                await cls._ws_connection.send(execute_request)
                # [æ›´æ–°] ä½¿ç”¨æ–°çš„æ¶ˆæ¯å¤„ç†å‡½æ•°
                result = await asyncio.wait_for(
                    cls._process_execution_messages(msg_id),
                    timeout=cls.EXECUTION_TIMEOUT
                )
            except asyncio.TimeoutError:
                l.warning(f"ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆè¶…è¿‡ {cls.EXECUTION_TIMEOUT} ç§’ï¼‰ã€‚")
                result = ExecutionResult(
                    status="timeout", type='timeout_error',
                    value=f"ä»£ç æ‰§è¡Œè¶…æ—¶ï¼ˆè¶…è¿‡ {cls.EXECUTION_TIMEOUT} ç§’ï¼‰ã€‚"
                )
            except ConnectionClosed:
                l.error("è¿æ¥åœ¨å‘é€å‰æˆ–å‘é€è¿‡ç¨‹ä¸­è¢«å…³é—­ã€‚")
                result = ExecutionResult(status="error", type='connection_error', value="æ‰§è¡Œå¼•æ“è¿æ¥ä¸¢å¤±ã€‚")

            if not is_initialization:
                end_time = time.monotonic()
                duration = (end_time - start_time) * 1000
                l.info(f"â¹ï¸  ä»£ç æ‰§è¡Œå®Œæˆ. çŠ¶æ€: {result.status.upper()}, è€—æ—¶: {duration:.2f} ms")

            return result

    @classmethod
    async def _process_execution_messages(cls, msg_id: str) -> ExecutionResult:
        """
        [é‡æ„] å¤„ç†ä» Kernel è¿”å›çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œç›´åˆ°æ‰§è¡ŒçŠ¶æ€å˜ä¸ºç©ºé—²ã€‚
        è¿™ä¸ªæ–°ç‰ˆæœ¬ä¼šç´¯ç§¯ç»“æœï¼Œä¼˜å…ˆè¿”å›å›¾åƒã€‚
        """
        assert cls._ws_connection is not None

        result_text_parts = []
        result_base64 = None
        error_output = None

        while True:
            try:
                message_raw = await cls._ws_connection.recv()
                msg = json.loads(message_raw)
                l.debug(msg)

                if msg.get("parent_header", {}).get("msg_id") != msg_id:
                    continue

                msg_type = msg["msg_type"]
                content = msg.get("content", {})

                if msg_type == 'stream':
                    result_text_parts.append(content.get('text', ''))

                elif msg_type == 'execute_result':
                    result_text_parts.append(content.get('data', {}).get('text/plain', ''))

                elif msg_type == 'display_data':
                    if 'image/png' in content.get('data', {}):
                        # ä¼˜å…ˆä¿ç•™å›¾ç‰‡ç»“æœ
                        result_base64 = content['data']['image/png']

                elif msg_type == 'error':
                    error_output = f"{content.get('ename', 'Error')}: {content.get('evalue', '')}"
                    # å‡ºç°é”™è¯¯ï¼Œå¯ä»¥æå‰é€€å‡ºå¾ªç¯
                    break

                elif msg_type == 'status' and content.get('execution_state') == 'idle':
                    # è¿™æ˜¯æ‰§è¡Œç»“æŸçš„ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯
                    break

            except (ConnectionClosed, WebSocketException) as e:
                return ExecutionResult(status="error", type='connection_error',
                                       value=f"æ‰§è¡Œå¼•æ“è¿æ¥ä¸¢å¤±: {type(e).__name__}")
            except Exception as e:
                return ExecutionResult(status="error", type='processing_error', value=f"å‘ç”Ÿæ„å¤–çš„å¤„ç†é”™è¯¯: {e}")

        # -- å¾ªç¯ç»“æŸåï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ç»“æœå†³å®šæœ€ç»ˆè¿”å›å€¼ --
        if error_output:
            return ExecutionResult(status="error", type='execution_error', value=error_output)

        if result_base64:
            return ExecutionResult(status="ok", type='image_png_base64', value=result_base64)

        final_text = "".join(result_text_parts)
        return ExecutionResult(status="ok", type='text', value=final_text)

```

--- 

`worker\main.py`

```python
"""
Main FastAPI application for the Python Code Interpreter WORKER service.
Authentication is handled by the Gateway. This service is not exposed publicly.
"""
import asyncio
from fastapi import FastAPI, HTTPException, status
from loguru import logger as l

from dto import ExecuteRequest, ExecuteResponse
from kernel_manager import JupyterKernelManager

# --- Application Lifecycle ---
async def _lifespan(app: FastAPI):
    l.info("Worker is starting up...")
    await JupyterKernelManager.start_kernel()
    yield
    l.info("Worker is shutting down...")

# --- FastAPI Application Instance ---
app = FastAPI(
    title="Python Code Interpreter Worker",
    lifespan=_lifespan,
)

# --- API Endpoints ---
@app.get("/health")
async def get_health_status():
    if await JupyterKernelManager.is_healthy():
        return {"status": "ok"}
    raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="Kernel is not healthy")

@app.post("/reset", status_code=status.HTTP_204_NO_CONTENT)
async def reset_python_kernel():
    if not await JupyterKernelManager.reset_kernel():
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to reset Python kernel.",
        )

@app.post("/execute", response_model=ExecuteResponse)
async def execute_python_code(request: ExecuteRequest) -> ExecuteResponse:
    result = await JupyterKernelManager.execute_code(request.code)

    if result.status == "ok":
        return ExecuteResponse(
            result_base64=result.value if result.type == 'image_png_base64' else None,
            result_text=result.value if result.type != 'image_png_base64' else None,
        )
    elif result.status == "timeout":
        l.warning("Code execution timed out. Triggering kernel auto-reset.")
        asyncio.create_task(JupyterKernelManager.reset_kernel())
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Code execution timed out after {JupyterKernelManager.EXECUTION_TIMEOUT} seconds. Environment has been reset.",
        )
    else:  # status == "error"
        l.warning(f"Python execution failed. Type: {result.type}, Message: {result.value}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Python Execution Error: {result.value}",
        )

```

--- 

`worker\requirements.txt`

```
# --- Core Application ---
fastapi
uvicorn[standard]
loguru
httpx
pydantic
websockets
aiofiles

# --- Jupyter Kernel Backend ---
jupyter-kernel-gateway==3.0.1
ipykernel

# --- Scientific Computing Libraries ---
numpy
pandas
sympy
scipy
matplotlib
scikit-learn

```
